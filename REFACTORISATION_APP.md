# Guide de Refactorisation - app.py

Ce document explique comment int√©grer proprement le module `distributed_manager.py` dans `app.py` pour d√©coupler compl√®tement le mode distribu√©.

---

## üéØ Objectif

Remplacer les imports directs et la logique distribu√©e dans `app.py` par des appels au module unifi√© `distributed_manager.py`.

**B√©n√©fices**:
- ‚úÖ Code principal ne d√©pend plus de redis/celery
- ‚úÖ Mode distribu√© optionnel (pas d'erreur si d√©pendances manquantes)
- ‚úÖ Gestion d'erreur robuste et messages clairs
- ‚úÖ Plus facile √† tester et maintenir

---

## üìù Modifications √† Apporter

### 1. Imports au d√©but du fichier

**Fichier**: `app.py`

#### ‚ùå Avant (lignes 271-277)

```python
from lib.functions import SessionContext, convert_ebook_batch, convert_ebook, web_interface

# Plus loin dans le code...
if args.get('worker_mode', False):
    from lib.distributed.worker import start_worker  # Import direct
    worker_id = os.getenv('WORKER_ID', 'worker_1')
    gpu_id = os.getenv('CUDA_VISIBLE_DEVICES')
    start_worker(worker_id=worker_id, gpu_id=gpu_id)
```

#### ‚úÖ Apr√®s

```python
from lib.functions import SessionContext, convert_ebook_batch, convert_ebook, web_interface

# Import du module distribu√© (seulement si disponible)
try:
    from lib.distributed_manager import (
        is_distributed_mode_available,
        initialize_coordinator,
        initialize_worker,
        DistributedModeError
    )
    DISTRIBUTED_MODE_AVAILABLE = True
except ImportError:
    DISTRIBUTED_MODE_AVAILABLE = False
    logger.warning("Distributed mode not available. Install: pip install -r requirements-distributed.txt")
```

**Explication**:
- Import dans un `try/except` pour g√©rer l'absence des d√©pendances
- Flag `DISTRIBUTED_MODE_AVAILABLE` pour d√©cider si on ajoute les arguments CLI

---

### 2. Arguments CLI Conditionnels

**Fichier**: `app.py` (lignes 226-231)

#### ‚ùå Avant

```python
# Distributed mode options (toujours ajout√©s)
distributed_group = parser.add_argument_group(
    '**** Distributed Mode Options (for multi-machine parallelism)',
    'Optional'
)
distributed_group.add_argument(options[27], action='store_true', ...)
distributed_group.add_argument(options[28], type=int, default=1, ...)
distributed_group.add_argument(options[29], type=str, ...)
distributed_group.add_argument(options[30], action='store_true', ...)
```

#### ‚úÖ Apr√®s

```python
# Distributed mode options (seulement si disponible)
if DISTRIBUTED_MODE_AVAILABLE:
    distributed_group = parser.add_argument_group(
        '**** Distributed Mode Options (for multi-machine parallelism)',
        'Optional'
    )
    distributed_group.add_argument(
        '--distributed',
        action='store_true',
        help='(Optional) Enable distributed processing mode using Celery + Redis.'
    )
    distributed_group.add_argument(
        '--num_workers',
        type=int,
        default=1,
        help='(Optional) Number of workers for distributed processing. Default: 1.'
    )
    distributed_group.add_argument(
        '--redis_url',
        type=str,
        default='redis://localhost:6379/0',
        help='(Optional) Redis URL for distributed coordination.'
    )
    distributed_group.add_argument(
        '--worker_mode',
        action='store_true',
        help='(Optional) Start as a Celery worker (not coordinator).'
    )
else:
    # Informer l'utilisateur que le mode distribu√© n'est pas disponible
    logger.info(
        "Distributed mode arguments not available. "
        "Install with: pip install -r requirements-distributed.txt"
    )
```

**Explication**:
- Arguments ajout√©s **seulement si** le mode distribu√© est disponible
- Message informatif si les d√©pendances manquent

---

### 3. Gestion du Mode Worker

**Fichier**: `app.py` (lignes 274-281)

#### ‚ùå Avant

```python
# Check if starting as worker
if args.get('worker_mode', False):
    print("Starting Celery worker...")
    from lib.distributed.worker import start_worker
    worker_id = os.getenv('WORKER_ID', 'worker_1')
    gpu_id = os.getenv('CUDA_VISIBLE_DEVICES')
    start_worker(worker_id=worker_id, gpu_id=gpu_id)
    return  # Exit after worker stops
```

#### ‚úÖ Apr√®s

```python
# Check if starting as worker
if args.get('worker_mode', False):
    if not DISTRIBUTED_MODE_AVAILABLE:
        error = (
            "Cannot start worker: distributed mode dependencies not installed.\n"
            "Install with: pip install -r requirements-distributed.txt"
        )
        print(error)
        sys.exit(1)

    print("Starting Celery worker...")
    try:
        worker_id = os.getenv('WORKER_ID', 'worker_1')
        gpu_id = os.getenv('CUDA_VISIBLE_DEVICES')
        redis_url = args.get('redis_url') or os.getenv('REDIS_URL', 'redis://localhost:6379/0')

        # Utiliser le module unifi√©
        initialize_worker(
            worker_id=worker_id,
            gpu_id=gpu_id,
            redis_url=redis_url
        )
    except DistributedModeError as e:
        error = f"Failed to start worker: {e}"
        print(error)
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nWorker stopped by user")
        sys.exit(0)

    return  # Exit after worker stops
```

**Explication**:
- V√©rification pr√©coce de `DISTRIBUTED_MODE_AVAILABLE`
- Utilisation de `initialize_worker()` du module unifi√©
- Gestion propre des erreurs avec `DistributedModeError`
- Support de Ctrl+C pour arr√™ter proprement

---

### 4. Mode Coordinator dans Headless

**Fichier**: `app.py` (apr√®s ligne 329)

#### Code √† Ajouter

```python
# Dans la section headless (apr√®s ligne 329)
if args['ebook']:
    args['ebook'] = os.path.abspath(args['ebook'])
    if not os.path.exists(args['ebook']):
        error = f'Error: The provided --ebook "{args["ebook"]}" does not exist.'
        print(error)
        sys.exit(1)

    # ‚úÖ NOUVEAU: Support du mode distribu√©
    if args.get('distributed', False):
        if not DISTRIBUTED_MODE_AVAILABLE:
            error = (
                "Cannot use distributed mode: dependencies not installed.\n"
                "Install with: pip install -r requirements-distributed.txt"
            )
            print(error)
            sys.exit(1)

        # Mode distribu√©
        try:
            from lib.distributed_manager import distribute_conversion

            # Initialiser coordinator
            initialize_coordinator(
                session_id=args['session'] or f"distributed_{uuid.uuid4().hex[:8]}",
                num_workers=args.get('num_workers', 1),
                redis_url=args.get('redis_url')
            )

            print(f"Distributed conversion with {args['num_workers']} workers...")

            # TODO: Adapter convert_ebook pour retourner chapitres
            # Pour l'instant, utiliser le mode normal
            progress_status, passed = convert_ebook(args, ctx)

            # Future impl√©mentation:
            # chapters = extract_chapters_from_ebook(args['ebook'])
            # tts_config = build_tts_config(args)
            # result = distribute_conversion(
            #     chapters=chapters,
            #     tts_config=tts_config,
            #     output_path=output_path,
            #     resume=args.get('force_restart') is not True
            # )

        except DistributedModeError as e:
            error = f'Distributed conversion failed: {e}'
            print(error)
            sys.exit(1)
    else:
        # Mode normal (non distribu√©)
        progress_status, passed = convert_ebook(args, ctx)

    if passed is False:
        error = f'Conversion failed: {progress_status}'
        print(error)
        sys.exit(1)
```

**Explication**:
- V√©rification de `args.get('distributed')` pour activer le mode
- Validation des d√©pendances avant de commencer
- Utilisation du module unifi√©
- TODO pour int√©gration compl√®te (n√©cessite refactoring de `convert_ebook`)

---

## üîß Int√©gration Compl√®te dans functions.py

Pour une int√©gration compl√®te, il faut aussi adapter `lib/functions.py` pour supporter le mode distribu√©.

**Fichier**: `lib/functions.py`

### Nouvelle Fonction √† Ajouter

```python
def convert_ebook_distributed(args, ctx):
    """
    Convertit un ebook en audiobook en mode distribu√©.

    Cette fonction:
    1. Extrait les chapitres de l'ebook
    2. Pr√©pare la configuration TTS
    3. Distribue aux workers via DistributedManager
    4. Combine les r√©sultats
    5. G√©n√®re le fichier final

    Args:
        args: Arguments de conversion (dict)
        ctx: SessionContext

    Returns:
        (progress_status, passed): Tuple (message, bool)
    """
    from lib.distributed_manager import (
        get_distributed_manager,
        distribute_conversion,
        DistributedModeError
    )

    session = ctx.get_session(args['session'])

    try:
        # 1. Extraire chapitres (r√©utiliser code existant)
        print("Extracting chapters from ebook...")
        chapters = extract_chapters_from_ebook(
            ebook_path=args['ebook'],
            language=args['language']
        )

        if not chapters:
            return ("No chapters found in ebook", False)

        print(f"Found {len(chapters)} chapters")

        # 2. Pr√©parer configuration TTS
        tts_config = {
            'model_name': args.get('tts_engine', 'xtts'),
            'voice_name': args.get('voice'),
            'language': args['language'],
            'device': args.get('device', 'cuda'),
            'custom_model': args.get('custom_model'),
            'temperature': args.get('temperature'),
            'speed': args.get('speed'),
            # ... autres param√®tres TTS
        }

        # 3. Pr√©parer chemin de sortie
        output_filename = f"{session['filename_noext']}.{args['output_format']}"
        output_path = os.path.join(args['audiobooks_dir'], output_filename)

        # 4. Distribuer conversion
        print(f"Distributing to {args.get('num_workers', 1)} workers...")

        final_path = distribute_conversion(
            chapters=chapters,
            tts_config=tts_config,
            output_path=output_path,
            resume=not args.get('force_restart', False)
        )

        # 5. Ajouter m√©tadonn√©es (r√©utiliser code existant)
        print("Adding metadata...")
        add_metadata_to_audiobook(
            audio_path=final_path,
            metadata=session['metadata'],
            cover=session.get('cover')
        )

        print(f"‚úÖ Distributed conversion completed: {final_path}")
        return (final_path, True)

    except DistributedModeError as e:
        error_msg = f"Distributed conversion failed: {e}"
        print(error_msg)
        return (error_msg, False)

    except Exception as e:
        error_msg = f"Unexpected error: {e}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return (error_msg, False)
```

### Modification de convert_ebook

```python
def convert_ebook(args, ctx):
    """Convertit un ebook (mode normal ou distribu√©)."""

    # D√©tecter si mode distribu√© demand√©
    if args.get('distributed', False):
        # V√©rifier disponibilit√©
        from lib.distributed_manager import is_distributed_mode_available

        if not is_distributed_mode_available():
            return (
                "Distributed mode not available. "
                "Install: pip install -r requirements-distributed.txt",
                False
            )

        # Utiliser fonction distribu√©e
        return convert_ebook_distributed(args, ctx)

    # Sinon, mode normal (code existant)
    # ... code existant ...
```

---

## üß™ Tests Recommand√©s

### Test 1: D√©pendances Manquantes

**Objectif**: V√©rifier que l'app fonctionne sans redis/celery install√©s

```bash
# D√©sinstaller redis/celery temporairement
pip uninstall -y redis celery

# Lancer l'app (mode normal)
python app.py --headless --ebook test.epub --language eng

# R√©sultat attendu: ‚úÖ Fonctionne (pas d'erreur)
```

### Test 2: Mode Distribu√© avec D√©pendances

**Objectif**: V√©rifier que le mode distribu√© fonctionne

```bash
# Installer d√©pendances
pip install -r requirements-distributed.txt

# D√©marrer Redis
docker run -d -p 6379:6379 --name test-redis redis:7-alpine

# D√©marrer worker
WORKER_ID=test_worker CUDA_VISIBLE_DEVICES=0 python app.py --worker_mode &

# Lancer conversion distribu√©e
python app.py --headless --distributed --num_workers 1 \
  --ebook test.epub --language eng

# R√©sultat attendu: ‚úÖ Conversion distribu√©e fonctionne
```

### Test 3: Mode Distribu√© sans Redis

**Objectif**: V√©rifier gestion d'erreur si Redis down

```bash
# Arr√™ter Redis
docker stop test-redis

# Tenter conversion distribu√©e
python app.py --headless --distributed --ebook test.epub

# R√©sultat attendu: ‚ùå Message d'erreur clair sur connexion Redis
```

---

## üìä Checklist de Migration

### √âtape 1: Pr√©paration

- [ ] Cr√©er branche `feature/refactor-distributed-mode`
- [ ] Backup du code actuel
- [ ] V√©rifier tests existants passent

### √âtape 2: Modifications app.py

- [ ] Ajouter imports conditionnels (section 1)
- [ ] Rendre arguments CLI conditionnels (section 2)
- [ ] Refactorer mode worker (section 3)
- [ ] Ajouter support coordinator headless (section 4)

### √âtape 3: Modifications functions.py

- [ ] Cr√©er fonction `convert_ebook_distributed()`
- [ ] Modifier fonction `convert_ebook()` pour router
- [ ] Cr√©er fonction `extract_chapters_from_ebook()`
- [ ] Cr√©er fonction `build_tts_config()`

### √âtape 4: Tests

- [ ] Test mode normal (sans d√©pendances distribu√©es)
- [ ] Test mode distribu√© (avec Redis)
- [ ] Test gestion d'erreur (Redis down)
- [ ] Test worker mode

### √âtape 5: Documentation

- [ ] Mettre √† jour README.md
- [ ] Mettre √† jour DISTRIBUTED_MODE.md
- [ ] Cr√©er exemples d'utilisation
- [ ] Documenter migration pour utilisateurs existants

### √âtape 6: Cleanup

- [ ] Supprimer/renommer `storage.py`
- [ ] Supprimer imports inutiles
- [ ] V√©rifier pas de r√©gression
- [ ] Merge dans main

---

## üîÑ Diff Complet app.py

Voici le diff complet des modifications √† apporter √† `app.py`:

```diff
--- a/app.py
+++ b/app.py
@@ -268,6 +268,18 @@ def main():
                 sys.exit(1)

+        # Import du module distribu√© (optionnel)
+        try:
+            from lib.distributed_manager import (
+                is_distributed_mode_available,
+                initialize_coordinator,
+                initialize_worker,
+                DistributedModeError
+            )
+            DISTRIBUTED_MODE_AVAILABLE = True
+        except ImportError:
+            DISTRIBUTED_MODE_AVAILABLE = False
+
         from lib.functions import SessionContext, convert_ebook_batch, convert_ebook, web_interface
         ctx = SessionContext()

@@ -225,11 +237,28 @@ def main():
     headless_optional_group.add_argument(options[25], action='version', version=f'ebook2audiobook version {prog_version}', help='''Show the version of the script and exit''')
     headless_optional_group.add_argument(options[26], action='store_true', help=argparse.SUPPRESS)

-    # Distributed mode options
-    distributed_group = parser.add_argument_group('**** Distributed Mode Options (for multi-machine parallelism)', 'Optional')
-    distributed_group.add_argument(options[27], action='store_true', help='''(Optional) Enable distributed processing mode using Celery + Redis. Audio files are transferred directly via Redis (no shared storage needed).''')
-    distributed_group.add_argument(options[28], type=int, default=1, help='''(Optional) Number of workers for distributed processing. Default: 1.''')
-    distributed_group.add_argument(options[29], type=str, default='redis://localhost:6379/0', help='''(Optional) Redis URL for distributed coordination. Default: redis://localhost:6379/0.''')
-    distributed_group.add_argument(options[30], action='store_true', help='''(Optional) Start as a Celery worker (not coordinator).''')
+    # Distributed mode options (conditionnels)
+    if 'DISTRIBUTED_MODE_AVAILABLE' in globals() and DISTRIBUTED_MODE_AVAILABLE:
+        distributed_group = parser.add_argument_group('**** Distributed Mode Options (for multi-machine parallelism)', 'Optional')
+        distributed_group.add_argument('--distributed', action='store_true', help='''(Optional) Enable distributed processing mode using Celery + Redis.''')
+        distributed_group.add_argument('--num_workers', type=int, default=1, help='''(Optional) Number of workers for distributed processing. Default: 1.''')
+        distributed_group.add_argument('--redis_url', type=str, default='redis://localhost:6379/0', help='''(Optional) Redis URL for distributed coordination.''')
+        distributed_group.add_argument('--worker_mode', action='store_true', help='''(Optional) Start as a Celery worker (not coordinator).''')

@@ -273,9 +302,27 @@ def main():

         # Check if starting as worker
         if args.get('worker_mode', False):
+            if not DISTRIBUTED_MODE_AVAILABLE:
+                error = "Cannot start worker: distributed mode dependencies not installed.\nInstall: pip install -r requirements-distributed.txt"
+                print(error)
+                sys.exit(1)
+
             print("Starting Celery worker...")
-            from lib.distributed.worker import start_worker
-            worker_id = os.getenv('WORKER_ID', 'worker_1')
-            gpu_id = os.getenv('CUDA_VISIBLE_DEVICES')
-            start_worker(worker_id=worker_id, gpu_id=gpu_id)
+            try:
+                worker_id = os.getenv('WORKER_ID', 'worker_1')
+                gpu_id = os.getenv('CUDA_VISIBLE_DEVICES')
+                redis_url = args.get('redis_url') or os.getenv('REDIS_URL', 'redis://localhost:6379/0')
+
+                initialize_worker(
+                    worker_id=worker_id,
+                    gpu_id=gpu_id,
+                    redis_url=redis_url
+                )
+            except DistributedModeError as e:
+                error = f"Failed to start worker: {e}"
+                print(error)
+                sys.exit(1)
+            except KeyboardInterrupt:
+                print("\nWorker stopped by user")
+                sys.exit(0)
             return  # Exit after worker stops
```

---

## üéâ R√©sultat Final

Apr√®s ces modifications:

‚úÖ **Code d√©coupl√©**: Mode distribu√© compl√®tement s√©par√©
‚úÖ **Optionnel**: Fonctionne sans redis/celery
‚úÖ **Robuste**: Gestion d'erreur compl√®te
‚úÖ **Maintenable**: Un seul point d'entr√©e (`distributed_manager.py`)
‚úÖ **Testable**: Facile √† mocker et tester

**Temps estim√©**: 2-3 heures pour migration compl√®te

---

**Cr√©√© le**: 2025-11-07
**Pour la branch**: `claude/distributed-parallelism-mode-011CUsL6fxY6ugbvLQN1LXBw`
