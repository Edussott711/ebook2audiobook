# Configuration pour le mode distribué client-serveur
# Copier ce fichier vers .env et ajuster les valeurs

# ============================================================================
# ARCHITECTURE
# ============================================================================
DISTRIBUTED_MODE=client-server
# Options: sequential (par défaut), client-server

# ============================================================================
# MASTER (SERVEUR) CONFIGURATION
# ============================================================================
# Liste des workers au format IP:PORT séparés par virgules
WORKER_NODES=localhost:8001,localhost:8002,localhost:8003
# Pour cluster Docker: worker1:8000,worker2:8000,worker3:8000
# Pour multi-machines: 192.168.1.10:8000,192.168.1.11:8000,192.168.1.12:8000

# Timeout pour requêtes aux workers (secondes)
WORKER_REQUEST_TIMEOUT=3600
# 3600 = 1 heure max par chapitre

# Stratégie de distribution
LOAD_BALANCING_STRATEGY=round-robin
# Options: round-robin, least-loaded, random

# Nombre de retries en cas d'échec
MAX_RETRIES_PER_CHAPTER=3

# ============================================================================
# WORKER (CLIENT) CONFIGURATION
# ============================================================================
WORKER_PORT=8000
# Port d'écoute du worker

WORKER_ID=worker1
# Identifiant unique du worker (pour logs)

TTS_MODEL=xtts
# Modèle TTS à charger: xtts, bark, vits, etc.

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
# ID du GPU à utiliser (0, 1, 2...)
# Laisser vide pour CPU
# Pour multi-GPU sur même machine: définir par worker

# ============================================================================
# LOGGING
# ============================================================================
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR

# ============================================================================
# MONITORING (optionnel)
# ============================================================================
ENABLE_METRICS=false
# Activer les métriques Prometheus

METRICS_PORT=9090
# Port pour /metrics endpoint

# ============================================================================
# PERFORMANCE TUNING
# ============================================================================
# Nombre de threads pour I/O async
UVICORN_WORKERS=1
# Généralement 1 pour isolation GPU

# Taille max de payload (MB)
MAX_PAYLOAD_SIZE=100
# Limite pour audio en base64

# ============================================================================
# NETWORK
# ============================================================================
# Pour déploiement multi-machines
MASTER_HOST=0.0.0.0
# Interface d'écoute du master (0.0.0.0 = toutes)

MASTER_PORT=5000
# Port API master (optionnel, pour monitoring)

# ============================================================================
# DEVELOPMENT / DEBUGGING
# ============================================================================
DEBUG_MODE=false
# Active logs détaillés et hot-reload

SKIP_TTS_MODEL_LOAD=false
# Pour tests sans GPU (retourne audio vide)

SIMULATE_PROCESSING_DELAY=0
# Simule délai de traitement (secondes) pour tests

# ============================================================================
# EXEMPLES DE CONFIGURATION
# ============================================================================

# Configuration locale (dev):
# WORKER_NODES=localhost:8001,localhost:8002
# WORKER_PORT=8001  (sur terminal 1)
# WORKER_PORT=8002  (sur terminal 2)

# Configuration Docker Compose:
# WORKER_NODES=worker1:8000,worker2:8000,worker3:8000
# (Les noms de services Docker sont résolus automatiquement)

# Configuration cluster multi-machines:
# MASTER_HOST=0.0.0.0
# WORKER_NODES=192.168.1.10:8000,192.168.1.11:8000,192.168.1.12:8000
# Sur chaque worker machine:
#   WORKER_PORT=8000
#   CUDA_VISIBLE_DEVICES=0 (ou 1, 2, selon GPU disponible)
