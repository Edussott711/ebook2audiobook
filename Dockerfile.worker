# Dockerfile pour les workers du mode client-serveur distribué
# Basé sur le Dockerfile principal mais lance le worker server

# Utiliser le même Dockerfile de base pour cohérence
ARG BASE_IMAGE=python:3.10-slim
FROM ${BASE_IMAGE}

# Arguments de build
ARG DEBIAN_FRONTEND=noninteractive
ARG PYTORCH_VERSION=cpu

WORKDIR /app

# Installation des dépendances système
RUN apt-get update && apt-get install -y \
    ffmpeg \
    git \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copier et installer les requirements Python
COPY requirements.txt requirements-client-server.txt ./
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install --no-cache-dir -r requirements-client-server.txt

# Installer PyTorch (version selon arg)
RUN if [ "$PYTORCH_VERSION" = "cuda" ]; then \
        pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; \
    else \
        pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu; \
    fi

# Copier le code de l'application
COPY . .

# Créer répertoires nécessaires
RUN mkdir -p /app/models /app/tmp

# Variables d'environnement par défaut
ENV WORKER_PORT=8000 \
    WORKER_ID=worker \
    TTS_MODEL=xtts \
    LOG_LEVEL=INFO

# Exposer le port du worker
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Démarrer le worker server
CMD ["python", "lib/distributed/worker_server.py"]
