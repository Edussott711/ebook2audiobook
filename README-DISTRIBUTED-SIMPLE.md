# Mode DistribuÃ© Client-Serveur - Guide Rapide

## ğŸš€ DÃ©marrage ultra-rapide (3 minutes)

### PrÃ©requis
- Docker + Docker Compose
- GPU NVIDIA (optionnel mais recommandÃ©)

### Installation

```bash
# 1. Cloner le repo (si pas dÃ©jÃ  fait)
git clone https://github.com/yourusername/ebook2audiobook.git
cd ebook2audiobook

# 2. DÃ©marrer le cluster (lance workers + master)
./scripts/start-client-server.sh

# 3. AccÃ©der Ã  l'interface web
open http://localhost:7860

# 4. Uploader un ebook et lancer la conversion !
```

C'est tout ! ğŸ‰

---

## ğŸ“– Qu'est-ce que le mode distribuÃ© ?

Le mode distribuÃ© permet de **parallÃ©liser la conversion TTS** en utilisant plusieurs machines (ou GPUs).

### Sans mode distribuÃ© (sÃ©quentiel)
```
Livre de 100 chapitres â†’ 10 heures â±ï¸
```

### Avec mode distribuÃ© (3 workers)
```
Livre de 100 chapitres â†’ 3.5 heures â±ï¸  (3x plus rapide!)
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MASTER        â”‚  Coordonne la conversion
â”‚  (Serveur)     â”‚  Distribue les chapitres
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼         â–¼         â–¼         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚Workerâ”‚  â”‚Workerâ”‚  â”‚Workerâ”‚  â”‚Workerâ”‚
    â”‚  1   â”‚  â”‚  2   â”‚  â”‚  3   â”‚  â”‚  N   â”‚
    â”‚GPU 0 â”‚  â”‚GPU 1 â”‚  â”‚GPU 2 â”‚  â”‚GPU N â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
      TTS       TTS       TTS       TTS
```

**Fonctionnement** :
1. Master parse l'ebook en chapitres
2. Envoie chaque chapitre Ã  un worker disponible (via HTTP)
3. Worker traite le TTS et retourne l'audio
4. Master assemble tous les chapitres en audiobook final

---

## ğŸ¯ Cas d'usage

### Vous devriez utiliser le mode distribuÃ© si :
âœ… Vous avez plusieurs GPUs (mÃªme machine ou diffÃ©rentes machines)
âœ… Vous convertissez des livres longs (>10 chapitres)
âœ… Vous voulez diviser le temps de traitement par N (N = nombre de workers)

### Restez en mode sÃ©quentiel si :
âŒ Vous n'avez qu'1 seul GPU
âŒ Vous convertissez de petits textes (<5 chapitres)
âŒ Vous prÃ©fÃ©rez la simplicitÃ©

---

## âš™ï¸ Configuration

### Configuration basique (Docker Compose)

Le fichier `docker-compose.client-server.yml` est dÃ©jÃ  configurÃ© pour 3 workers.

**Pour ajuster le nombre de workers** :
1. Ã‰diter `docker-compose.client-server.yml`
2. Commenter/dÃ©commenter les sections `worker1`, `worker2`, `worker3`, etc.
3. Mettre Ã  jour `WORKER_NODES` dans la section `master`

### Configuration multi-machines

**Sur la machine Master** :
```bash
# docker-compose.client-server.yml
environment:
  - WORKER_NODES=192.168.1.10:8000,192.168.1.11:8000,192.168.1.12:8000
```

**Sur chaque machine Worker** :
```bash
# Lancer le worker
docker run -d \
  --gpus all \
  -p 8000:8000 \
  -e WORKER_PORT=8000 \
  -e CUDA_VISIBLE_DEVICES=0 \
  ebook2audiobook:worker
```

---

## ğŸ“Š Monitoring

### VÃ©rifier la santÃ© des workers

```bash
# Worker 1
curl http://localhost:8001/health

# RÃ©ponse:
{
  "status": "healthy",
  "gpu_available": true,
  "model_loaded": true
}
```

### Voir le statut d'un worker

```bash
curl http://localhost:8001/status

# RÃ©ponse:
{
  "status": "idle",  # ou "busy"
  "current_chapter": null,
  "gpu_memory_free_mb": 15360,
  "uptime_seconds": 3600
}
```

### Logs en temps rÃ©el

```bash
# Master
docker logs -f ebook2audio-master

# Worker 1
docker logs -f ebook2audio-worker1
```

---

## ğŸ› Troubleshooting

### Workers ne dÃ©marrent pas

**SymptÃ´me** : `docker ps` ne montre pas les workers

**Solutions** :
1. VÃ©rifier les logs : `docker logs ebook2audio-worker1`
2. VÃ©rifier que les GPUs sont accessibles : `nvidia-smi`
3. VÃ©rifier la configuration Docker GPU : `docker run --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi`

---

### Worker rÃ©pond "503 Service Unavailable"

**SymptÃ´me** : `curl http://localhost:8001/health` retourne 503

**Raison** : Worker est occupÃ© Ã  traiter un chapitre

**Solution** : Attendre que le chapitre se termine, ou ajouter plus de workers

---

### Conversion trÃ¨s lente

**Diagnostic** :
```bash
# VÃ©rifier que les workers sont utilisÃ©s
docker logs ebook2audio-master | grep "Processing chapter"

# Doit montrer des logs comme:
# worker1: Processing chapter 1
# worker2: Processing chapter 2
# worker3: Processing chapter 3
```

**Si pas de parallÃ©lisme** :
- VÃ©rifier que `--distributed` est passÃ© Ã  la commande
- VÃ©rifier que `WORKER_NODES` est bien configurÃ© dans master

---

### GPU out of memory

**SymptÃ´me** :
```
RuntimeError: CUDA out of memory
```

**Solutions** :
1. RÃ©duire le nombre de workers (1 worker = 1 GPU)
2. S'assurer que `CUDA_VISIBLE_DEVICES` est unique par worker
3. Utiliser un modÃ¨le TTS plus lÃ©ger

---

## ğŸ”§ Commandes utiles

```bash
# DÃ©marrer le cluster
./scripts/start-client-server.sh

# ArrÃªter le cluster
docker-compose -f docker-compose.client-server.yml down

# RedÃ©marrer un worker
docker-compose -f docker-compose.client-server.yml restart worker1

# Voir les containers
docker-compose -f docker-compose.client-server.yml ps

# AccÃ©der au shell d'un worker
docker exec -it ebook2audio-worker1 bash

# Tester un worker manuellement
curl -X POST http://localhost:8001/process_chapter \
  -H "Content-Type: application/json" \
  -d '{
    "chapter_id": 1,
    "sentences": ["Hello world."],
    "tts_config": {"voice_name": "jenny", "language": "en", "model_name": "xtts"}
  }'
```

---

## ğŸ“š Documentation complÃ¨te

Pour plus de dÃ©tails, consulter :

- **[CLIENT_SERVER_ARCHITECTURE.md](CLIENT_SERVER_ARCHITECTURE.md)** - Architecture dÃ©taillÃ©e
- **[ARCHITECTURE_COMPARISON.md](ARCHITECTURE_COMPARISON.md)** - Comparaison Celery vs Client-Serveur
- **[IMPLEMENTATION_GUIDE.md](IMPLEMENTATION_GUIDE.md)** - Guide d'implÃ©mentation

---

## â“ FAQ

**Q: Combien de workers puis-je avoir ?**
R: Autant que de GPUs disponibles. En pratique, 2-10 workers est optimal.

**Q: Puis-je mixer GPUs et CPUs ?**
R: Oui, mais les workers CPU seront beaucoup plus lents.

**Q: Les workers doivent-ils avoir le mÃªme GPU ?**
R: Non, mais les performances seront limitÃ©es par le GPU le plus lent.

**Q: Puis-je ajouter/retirer des workers pendant une conversion ?**
R: Non, pas dans cette version. ArrÃªtez et relancez le cluster.

**Q: Quelle est la consommation rÃ©seau ?**
R: Environ 1-5MB par chapitre (transfert audio). NÃ©gligeable sur rÃ©seau local.

---

## ğŸ‰ RÃ©sultat attendu

Avec 3 workers GPU :
- Livre de 50 chapitres
- Mode sÃ©quentiel : ~6 heures
- **Mode distribuÃ© : ~2 heures** âš¡

**Gain : 3x plus rapide !**

---

**Bon audiobook ! ğŸµ**
