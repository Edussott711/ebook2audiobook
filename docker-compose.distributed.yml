version: '3.8'

# Distributed Mode Docker Compose - No Shared Storage Required
# Audio files are transferred directly via Redis using base64 encoding
#
# Usage:
#   1. Start on coordinator machine: docker-compose -f docker-compose.distributed.yml up coordinator redis flower
#   2. Start on worker machines: docker run --gpus all -e REDIS_URL=redis://<coordinator-ip>:6379/0 ebook2audiobook-worker
#
# For multi-machine setup, see deployment scripts in scripts/distributed/

services:
  # Redis - Message broker, result backend, and audio transfer medium
  redis:
    image: redis:7-alpine
    container_name: ebook2audio-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-} --maxmemory 2gb --maxmemory-policy allkeys-lru
    networks:
      - ebook2audio-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  # Coordinator - Master node (runs on one machine)
  coordinator:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ebook2audio-coordinator
    environment:
      - REDIS_URL=redis://:${REDIS_PASSWORD:-}@redis:6379/0
      - NUM_WORKERS=${NUM_WORKERS:-2}
    ports:
      - "7860:7860"  # Gradio UI
    volumes:
      - ./input:/app/input
      - ./output:/app/output
      - ./models:/app/models
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ebook2audio-net
    command: >
      sh -c "echo 'Waiting for workers...' &&
             sleep 10 &&
             python app.py --script_mode full_docker"
    restart: unless-stopped

  # Worker - Processing nodes (run on machines with GPUs)
  # NOTE: For multi-machine setup, use docker run instead (see deployment scripts)
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    environment:
      - REDIS_URL=redis://:${REDIS_PASSWORD:-}@redis:6379/0
      - CUDA_VISIBLE_DEVICES=${WORKER_GPU_ID:-0}
      - WORKER_ID=${WORKER_ID:-worker}
    volumes:
      - ./models:/app/models
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ebook2audio-net
    deploy:
      replicas: ${NUM_WORKERS:-2}
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # Flower - Monitoring dashboard (optional)
  flower:
    image: mher/flower:2.0
    container_name: ebook2audio-flower
    environment:
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD:-}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD:-}@redis:6379/0
      - FLOWER_PORT=5555
      - FLOWER_BASIC_AUTH=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin}
    ports:
      - "5555:5555"
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - ebook2audio-net
    restart: unless-stopped

networks:
  ebook2audio-net:
    driver: bridge

volumes:
  redis_data:
    driver: local
